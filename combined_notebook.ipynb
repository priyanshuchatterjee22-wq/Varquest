{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552ffff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-allel pandas requests --quiet\n",
    "# If running in a constrained environment, consider installing via conda:\n",
    "# conda install -c conda-forge scikit-allel pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e103418",
   "metadata": {},
   "source": [
    "## Part 1: VCF parser (scikit-allel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d1a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part1_vcf_parser.py\n",
    "\n",
    "import pandas as pd\n",
    "import allel\n",
    "import numpy as np\n",
    "import gzip\n",
    "import io\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_vcf(vcf_file, alt_number=5):\n",
    "    \"\"\"Parse a VCF into a pandas DataFrame using scikit-allel.\n",
    "\n",
    "    This function tries to read the variants block from the VCF and\n",
    "    expand multi-allelic records into one row per ALT allele, producing\n",
    "    the same DataFrame shape as the previous implementation.\n",
    "    \"\"\"\n",
    "    # Handle gzipped files that may not have a .gz extension by\n",
    "    # checking the magic bytes. Provide a text file-like object\n",
    "    # to scikit-allel so it doesn't attempt to decode compressed bytes.\n",
    "    close_handle = False\n",
    "    fileobj = None\n",
    "\n",
    "    if isinstance(vcf_file, str):\n",
    "        # If path exists, inspect first two bytes for gzip magic\n",
    "        if os.path.exists(vcf_file):\n",
    "            try:\n",
    "                with open(vcf_file, 'rb') as fh:\n",
    "                    magic = fh.read(2)\n",
    "            except PermissionError as e:\n",
    "                import getpass\n",
    "                user = getpass.getuser()\n",
    "                msg = (\n",
    "                    f\"Permission denied when opening '{vcf_file}' for reading.\\n\"\n",
    "                    f\"Current user: {user}.\\n\"\n",
    "                    \"Possible causes: file is locked, insufficient NTFS permissions, or the file is open in another program.\\n\"\n",
    "                    \"Suggested checks:\\n\"\n",
    "                    \" - Verify file exists and is readable: in PowerShell run `Test-Path .\\\\sample.vcf`\\n\"\n",
    "                    \" - Inspect permissions: `Get-Acl .\\\\sample.vcf | Format-List` or `icacls .\\\\sample.vcf`\\n\"\n",
    "                    \" - If needed, grant read permission: `icacls .\\\\sample.vcf /grant \\\"$env:USERNAME\\\":(R)` (run as admin if required).\\n\"\n",
    "                    \" - Ensure no other program is locking the file (close editors/viewers).\\n\"\n",
    "                )\n",
    "                raise PermissionError(msg) from e\n",
    "            # scikit-allel requires either a file path string or binary file object,\n",
    "            # not a text mode file object. Pass the file path string directly.\n",
    "            fileobj = vcf_file\n",
    "        else:\n",
    "            # Pass through to allel which will raise a helpful error\n",
    "            fileobj = vcf_file\n",
    "    else:\n",
    "        # Assume file-like object was passed in\n",
    "        fileobj = vcf_file\n",
    "\n",
    "    # Read as many fields as scikit-allel provides; alt_number controls ALT columns\n",
    "    try:\n",
    "        vcf_dict = allel.read_vcf(fileobj, fields=None, alt_number=alt_number)\n",
    "    finally:\n",
    "        if close_handle and hasattr(fileobj, 'close'):\n",
    "            try:\n",
    "                fileobj.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Collect variant-level arrays returned under keys like 'variants/CHROM'\n",
    "    variants = {}\n",
    "    for k, v in vcf_dict.items():\n",
    "        if k.startswith('variants/'):\n",
    "            variants[k.split('/', 1)[1]] = v\n",
    "\n",
    "    n = len(variants.get('CHROM', []))\n",
    "    records = []\n",
    "\n",
    "    for i in range(n):\n",
    "        chrom = variants.get('CHROM')[i]\n",
    "        pos = int(variants.get('POS')[i]) if 'POS' in variants else None\n",
    "        ref = variants.get('REF')[i] if 'REF' in variants else None\n",
    "        alts = variants.get('ALT')[i] if 'ALT' in variants else []\n",
    "        qual = variants.get('QUAL')[i] if 'QUAL' in variants else None\n",
    "        vid = variants.get('ID')[i] if 'ID' in variants else None\n",
    "        filt = variants.get('FILTER')[i] if 'FILTER' in variants else None\n",
    "\n",
    "        # Build INFO dictionary from keys that start with 'INFO/' in the top-level dict\n",
    "        info_dict = {}\n",
    "        for k, arr in vcf_dict.items():\n",
    "            if k.startswith('INFO/'):\n",
    "                info_key = k.split('/', 1)[1]\n",
    "                try:\n",
    "                    info_val = arr[i]\n",
    "                except Exception:\n",
    "                    info_val = None\n",
    "                info_dict[info_key] = info_val\n",
    "\n",
    "        # Normalize ALT into a list of strings\n",
    "        if alts is None:\n",
    "            alts_list = []\n",
    "        elif isinstance(alts, (list, tuple, np.ndarray)):\n",
    "            alts_list = [a.decode() if isinstance(a, bytes) else str(a) for a in alts if a is not None]\n",
    "        else:\n",
    "            alts_list = [str(alts)]\n",
    "\n",
    "        for alt in alts_list:\n",
    "            records.append({\n",
    "                \"CHROM\": chrom,\n",
    "                \"POS\": pos,\n",
    "                \"REF\": ref,\n",
    "                \"ALT\": alt,\n",
    "                \"QUAL\": float(qual) if qual is not None else None,\n",
    "                \"ID\": vid.decode() if isinstance(vid, (bytes, bytearray)) else vid,\n",
    "                \"FILTER\": list(filt) if isinstance(filt, (list, tuple, np.ndarray)) else ([] if filt is None else [str(filt)]),\n",
    "                \"INFO\": info_dict,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6982ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CHROM, POS, REF, ALT, QUAL, ID, FILTER, INFO]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# part2_filter_variants.py\n",
    "\n",
    "def filter_variants(df, min_qual=30):\n",
    "    \"\"\"Filter variants by quality and keep rare ones\"\"\"\n",
    "    filtered = df[df[\"QUAL\"] >= min_qual].copy()\n",
    "\n",
    "    # Example filter: keep only SNPs\n",
    "    filtered = filtered[(filtered[\"REF\"].str.len() == 1) & (filtered[\"ALT\"].str.len() == 1)]\n",
    "\n",
    "    return filtered\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    from part_1 import parse_vcf\n",
    "    df = parse_vcf(\"sample/clinvar.vcf\")\n",
    "    filtered_df = filter_variants(df)\n",
    "    print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927234e",
   "metadata": {},
   "source": [
    "## Part 3: Annotation (original file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b043d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part3_annotation.py\n",
    "import requests\n",
    "\n",
    "def annotate_clinvar(variant):\n",
    "    \"\"\"Fetch Clinvar annontation using variant ID (rsID if available)\"\"\"\n",
    "    if variant.get(\"ID\") is None:\n",
    "        return None\n",
    "    \n",
    "    url = f\"https://api.ncbi.nlm.nih.gov/variation/v0/beta/refsnp/{variant['ID'].replace('rs','')}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "def annotate_myvariant(hgvs_notation):\n",
    "    \"\"\"Annotate variant using Myvariant.info\"\"\"\n",
    "    url = f\"https://myvariant.info/v1/variant/{hgvs_notation}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb9d8a",
   "metadata": {},
   "source": [
    "## Part 4: Prioritization (original file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "229ee174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part4_priorities.py\n",
    "def prioritize_variants(df, clinvar_annotations):\n",
    "    \"\"\"Mark variants that are rare and pathogenic\"\"\"\n",
    "    prioritized = []\n",
    "\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        clinvar = clinvar_annotations.get(row[\"ID\"], {})\n",
    "        if clinvar:\n",
    "            clinical_significance = clinvar.get(\"clinical_significance\", \"unknown\")\n",
    "            if \"pathogenic\" in clinical_significance.lower():\n",
    "                prioritized.append((row.to_dict(), clinvar))\n",
    "\n",
    "    return prioritized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c06f7",
   "metadata": {},
   "source": [
    "## Part 5: Reporting (original file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecae0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part5_report.py\n",
    "import pandas as pd\n",
    "\n",
    "def save_report(priotized_variants, output_file=\"varquest_report.csv\"):\n",
    "    \"\"\"Save prioritized variants into CSV\"\"\"\n",
    "    records = []\n",
    "\n",
    "\n",
    "    for variant, annotations in priotized_variants:\n",
    "        record.append({\n",
    "            \"CHROM\": variant[\"CHROM\"],\n",
    "            \"POS\": variant[\"POS\"] ,\n",
    "            \"REF\": variant[\"REF\"],\n",
    "            \"ALT\": variant[\"ALT\"],\n",
    "            \"ID\": variant[\"ID\"],\n",
    "            \"Clinvar_Significance\": annotations.get(\"clinical_significance\", \"NA\")\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(records).to_csv(output_file, index=False)\n",
    "    print(f\"Report saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c06a2",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "Run the parser on `sample.vcf` and show the first lines. Note: some of the other parts contain minor syntax or naming issues (see the Notes cell) and may need small fixes before running the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476b0beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CHROM    POS REF ALT  QUAL       ID FILTER INFO\n",
      "0     1  66926  AG   A   NaN  3385321     []   {}\n",
      "1     1  66926  AG       NaN  3385321     []   {}\n",
      "2     1  66926  AG       NaN  3385321     []   {}\n",
      "3     1  66926  AG       NaN  3385321     []   {}\n",
      "4     1  66926  AG       NaN  3385321     []   {}\n"
     ]
    }
   ],
   "source": [
    "# Usage example: parse clinvar.vcf.gz\n",
    "from part_1 import parse_vcf\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eb44c",
   "metadata": {},
   "source": [
    "## Notes and Known Issues\n",
    "- `part_2.py`, `part_5.py`, and `integrated.py` in the workspace contain syntax/name bugs (missing colons, wrong function names, typos).\n",
    "- I intentionally included the original files as reference; if you want, I can also fix those bugs and make the full pipeline runnable.\n",
    "- `scikit-allel` may require additional dependencies (NumPy, zarr) and can be installed via conda for the smoothest experience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
